import cv2
import mediapipe as mp
import numpy as np
from screeninfo import get_monitors
import json
import os
from datetime import datetime
import time
import random
import csv
import pandas as pd

def get_iris_center(landmarks, iris_indices, w, h):
    """í™ì±„ ì¤‘ì‹¬ì  ê³„ì‚°"""
    x_coords = [landmarks[idx].x * w for idx in iris_indices]
    y_coords = [landmarks[idx].y * h for idx in iris_indices]
    return int(np.mean(x_coords)), int(np.mean(y_coords))

def smooth_coordinates(coord_history, window_size=5):
    """ì¢Œí‘œ ìŠ¤ë¬´ë”© (ì´ë™í‰ê·  í•„í„°)"""
    if len(coord_history) < window_size:
        return coord_history[-1] if coord_history else (0, 0)
    
    recent_coords = coord_history[-window_size:]
    avg_x = int(np.mean([coord[0] for idx, coord in enumerate(recent_coords)]))
    avg_y = int(np.mean([coord[1] for idx, coord in enumerate(recent_coords)]))
    return avg_x, avg_y

def calculate_eye_movement_sync(left_eye_history, right_eye_history, threshold=10):
    """ì–‘ìª½ ëˆˆì˜ ì›€ì§ì„ ë™ê¸°í™” ì •ë„ ê³„ì‚°"""
    if len(left_eye_history) < 2 or len(right_eye_history) < 2:
        return 1.0
    
    # ìµœê·¼ ì›€ì§ì„ ë²¡í„° ê³„ì‚°
    left_dx = left_eye_history[-1][0] - left_eye_history[-2][0]
    left_dy = left_eye_history[-1][1] - left_eye_history[-2][1]
    right_dx = right_eye_history[-1][0] - right_eye_history[-2][0]
    right_dy = right_eye_history[-1][1] - right_eye_history[-2][1]
    
    # ì›€ì§ì„ ë°©í–¥ì˜ ìœ ì‚¬ë„ ê³„ì‚°
    left_magnitude = np.sqrt(left_dx**2 + left_dy**2)
    right_magnitude = np.sqrt(right_dx**2 + right_dy**2)
    
    if left_magnitude < threshold and right_magnitude < threshold:
        return 1.0  # ë‘˜ ë‹¤ ì •ì§€ ìƒíƒœ
    
    # ì›€ì§ì„ ë°©í–¥ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„
    if left_magnitude > 0 and right_magnitude > 0:
        dot_product = left_dx * right_dx + left_dy * right_dy
        cos_similarity = dot_product / (left_magnitude * right_magnitude)
        return max(0, cos_similarity)
    
    return 0.0

def generate_random_target_position(screen_width, screen_height, margin=100, current_pos=None, used_positions=None):
    """í™”ë©´ ì „ì²´ì—ì„œ ëœë¤í•œ ëª©í‘œ ìœ„ì¹˜ ìƒì„± (ê¸´ ê±°ë¦¬ ë³´ì¥, ì¤‘ë³µ ë°©ì§€)"""
    if current_pos is None:
        # ì²« ë²ˆì§¸ ìœ„ì¹˜ëŠ” ì™„ì „ ëœë¤
        x = random.randint(margin, screen_width - margin)
        y = random.randint(margin, screen_height - margin)
        return x, y
    
    # í˜„ì¬ ìœ„ì¹˜ì™€ ì¶©ë¶„íˆ ë©€ë¦¬ ë–¨ì–´ì§„ ìœ„ì¹˜ ìƒì„±
    current_x, current_y = current_pos
    attempts = 0
    max_attempts = 50  # ë” ë§ì€ ì‹œë„ í—ˆìš©
    
    while attempts < max_attempts:
        # í™”ë©´ ì „ì²´ì—ì„œ ëœë¤ ì„ íƒ
        x = random.randint(margin, screen_width - margin)
        y = random.randint(margin, screen_height - margin)
        
        # í˜„ì¬ ìœ„ì¹˜ì™€ì˜ ê±°ë¦¬ ê³„ì‚°
        distance = np.sqrt((x - current_x)**2 + (y - current_y)**2)
        
        # í™”ë©´ ëŒ€ê°ì„  ê±°ë¦¬ì˜ 60-80% ì´ìƒ ë–¨ì–´ì ¸ì•¼ í•¨
        screen_diagonal = np.sqrt(screen_width**2 + screen_height**2)
        min_distance = screen_diagonal * 0.6
        max_distance = screen_diagonal * 0.9
        
        # ì‚¬ìš©ëœ ìœ„ì¹˜ì™€ë„ ì¶©ë¶„íˆ ë–¨ì–´ì ¸ì•¼ í•¨
        too_close_to_used = False
        if used_positions:
            for used_pos in used_positions:
                used_distance = np.sqrt((x - used_pos[0])**2 + (y - used_pos[1])**2)
                if used_distance < min_distance * 0.5:  # ì‚¬ìš©ëœ ìœ„ì¹˜ì™€ ë„ˆë¬´ ê°€ê¹Œìš°ë©´ ì œì™¸
                    too_close_to_used = True
                    break
        
        if min_distance <= distance <= max_distance and not too_close_to_used:
            return x, y
        
        attempts += 1
    
    # ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ ì‹œ ê°•ì œë¡œ ë©€ë¦¬ ë–¨ì–´ì§„ ìœ„ì¹˜ ìƒì„±
    # í™”ë©´ì˜ ë°˜ëŒ€í¸ êµ¬ì—­ì—ì„œ ì„ íƒ
    if current_x < screen_width // 2:
        x = random.randint(screen_width - margin - 300, screen_width - margin)
    else:
        x = random.randint(margin, margin + 300)
    
    if current_y < screen_height // 2:
        y = random.randint(screen_height - margin - 300, screen_height - margin)
    else:
        y = random.randint(margin, margin + 300)
    
    return x, y

def run_random_eye_tracking_test():
    """ëœë¤ ìœ„ì¹˜ ë¹ ë¥¸ ì›€ì§ì„ ì•„ì´íŠ¸ë˜í‚¹ í…ŒìŠ¤íŠ¸"""
    print("ğŸ¯ ëœë¤ ìœ„ì¹˜ ë¹ ë¥¸ ì›€ì§ì„ ì•„ì´íŠ¸ë˜í‚¹ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # ëª¨ë‹ˆí„° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    monitor = get_monitors()[0]
    screen_width = monitor.width
    screen_height = monitor.height
    print(f"ğŸ“º ëª¨ë‹ˆí„° í¬ê¸°: {screen_width} x {screen_height}")
    
    # MediaPipe ì´ˆê¸°í™”
    mp_face_mesh = mp.solutions.face_mesh
    face_mesh = mp_face_mesh.FaceMesh(
        static_image_mode=False,
        max_num_faces=1,
        refine_landmarks=True,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    )
    
    # í™ì±„ ì¸ë±ìŠ¤
    left_iris = [474, 475, 476, 477]
    right_iris = [469, 470, 471, 472]
    
    # ì¹´ë©”ë¼ ì—´ê¸°
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("âœ… ì¹´ë©”ë¼ ì—°ê²° ì„±ê³µ!")
    print("ğŸ¯ í…ŒìŠ¤íŠ¸ ì„¤ëª…:")
    print("   ğŸš€ ë¹ ë¥¸ ì›€ì§ì„ìœ¼ë¡œ ë°˜ì‘ ì‹œê°„ ì¸¡ì •")
    print("   ğŸ² ëœë¤ ìœ„ì¹˜ë¡œ ë°˜ë³µí•™ìŠµ ë°©ì§€")
    print("   ğŸ“ í™”ë©´ ì „ì²´ í™œìš©í•œ ê¸´ ê±°ë¦¬ ì´ë™")
    print("   âš¡ ë¹ ë¥¸ ì •ì§€ë¡œ ê°‘ì‘ìŠ¤ëŸ¬ìš´ ë°©í–¥ ì „í™˜")
    print("â° 30ì´ˆ í›„ ìë™ ì¢…ë£Œë©ë‹ˆë‹¤.")
    print("ğŸ“± 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¦‰ì‹œ ì¢…ë£Œë©ë‹ˆë‹¤.")
    
    # OpenCV ì°½ ìƒì„± ë° ìµœëŒ€í™”
    cv2.namedWindow("ëœë¤ ì•„ì´íŠ¸ë˜í‚¹ í…ŒìŠ¤íŠ¸", cv2.WINDOW_NORMAL)
    cv2.setWindowProperty("ëœë¤ ì•„ì´íŠ¸ë˜í‚¹ í…ŒìŠ¤íŠ¸", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
    
    # í…ŒìŠ¤íŠ¸ ì‹œì‘ UI í‘œì‹œ
    print("ğŸš€ í…ŒìŠ¤íŠ¸ ì‹œì‘ UIë¥¼ í‘œì‹œí•©ë‹ˆë‹¤...")
    start_countdown = 5
    while start_countdown > 0:
        # ì‹œì‘ í™”ë©´ ìƒì„±
        start_screen = np.zeros((screen_height, screen_width, 3), dtype=np.uint8)
        
        # ì œëª©
        cv2.putText(start_screen, "Random Eye Tracking Test", 
                    (screen_width//2 - 400, screen_height//2 - 150), 
                    cv2.FONT_HERSHEY_SIMPLEX, 2.0, (255, 255, 255), 3)
        
        # ì¹´ìš´íŠ¸ë‹¤ìš´
        cv2.putText(start_screen, f"Starting test in {start_countdown} seconds...", 
                    (screen_width//2 - 300, screen_height//2), 
                    cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 3)
        
        # ì„¤ëª…
        cv2.putText(start_screen, "Follow the red dot to measure reaction time", 
                    (screen_width//2 - 350, screen_height//2 + 100), 
                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
        
        cv2.imshow("ëœë¤ ì•„ì´íŠ¸ë˜í‚¹ í…ŒìŠ¤íŠ¸", start_screen)
        cv2.waitKey(1000)  # 1ì´ˆ ëŒ€ê¸°
        start_countdown -= 1
    
    # í…ŒìŠ¤íŠ¸ ìƒíƒœ ë³€ìˆ˜
    test_start_time = time.time()
    
    # ëª¨ë“  ëª©í‘œì ì„ ë¯¸ë¦¬ ìƒì„±í•˜ì—¬ ìˆœì„œëŒ€ë¡œ ì‚¬ìš©
    all_targets = []
    for i in range(20):  # 20ê°œì˜ ëª©í‘œì  ë¯¸ë¦¬ ìƒì„±
        if i == 0:
            target = generate_random_target_position(screen_width, screen_height)
        else:
            # ì´ì „ ëª©í‘œì ê³¼ ì¶©ë¶„íˆ ë©€ë¦¬ ë–¨ì–´ì§„ ìœ„ì¹˜ ìƒì„±
            prev_target = all_targets[-1]
            target = generate_random_target_position(screen_width, screen_height, current_pos=prev_target)
        all_targets.append(target)
    
    current_target = all_targets[0]
    next_target = all_targets[1]
    target_index = 1
    
    print(f"ğŸ¯ ë¯¸ë¦¬ ìƒì„±ëœ ëª©í‘œì ë“¤:")
    for i, target in enumerate(all_targets[:5]):  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
        print(f"   {i}: {target}")
    
    # ì›€ì§ì„ ìƒíƒœ
    is_moving = False
    movement_start_time = None
    movement_duration = random.uniform(1.5, 3.0)  # 1.5~3ì´ˆê°„ ì´ë™
    stop_duration = random.uniform(0.8, 1.5)      # 0.8~1.5ì´ˆê°„ ì •ì§€
    
    # ëˆˆ ì›€ì§ì„ ê¸°ë¡
    left_eye_history = []
    right_eye_history = []
    reaction_times = []
    eye_sync_scores = []
    
    # CSV ë°ì´í„° ìˆ˜ì§‘ì„ ìœ„í•œ ë³€ìˆ˜ë“¤
    csv_data = []
    frame_count = 0
    
    # í…ŒìŠ¤íŠ¸ ê²°ê³¼
    test_results = {
        "total_movements": 0,
        "average_reaction_time": None,
        "eye_sync_scores": [],
        "movement_patterns": []
    }
    
    print(f"ğŸ¯ ì²« ë²ˆì§¸ ëª©í‘œ: {current_target}")
    print(f"ğŸ¯ ë‹¤ìŒ ëª©í‘œ: {next_target}")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
            
        # í”„ë ˆì„ ë’¤ì§‘ê¸°
        frame = cv2.flip(frame, 1)
        
        # í™ì±„ ì°¾ê¸°
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = face_mesh.process(rgb_frame)
        
        # í”„ë ˆì„ì„ ì „ì²´í™”ë©´ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        frame_fullscreen = cv2.resize(frame, (screen_width, screen_height))
        
        # í˜„ì¬ ì‹œê°„ ê³„ì‚°
        current_time = time.time()
        elapsed_time = current_time - test_start_time
        
        # ì›€ì§ì„ ìƒíƒœ ì—…ë°ì´íŠ¸
        if not is_moving:
            # ì •ì§€ ìƒíƒœì—ì„œ ë‹¤ìŒ ì›€ì§ì„ ì‹œì‘
            if movement_start_time is None:
                movement_start_time = current_time
            elif current_time - movement_start_time >= stop_duration:
                # ì •ì§€ ì‹œê°„ ì™„ë£Œ, ì›€ì§ì„ ì‹œì‘
                is_moving = True
                movement_start_time = current_time
                
                # ëª©í‘œì  ì—…ë°ì´íŠ¸: í˜„ì¬ ìœ„ì¹˜ë¥¼ ì´ì „ ëª©í‘œë¡œ, ë‹¤ìŒ ëª©í‘œë¥¼ í˜„ì¬ ëª©í‘œë¡œ
                current_target = next_target
                
                # ìƒˆë¡œìš´ ë‹¤ìŒ ëª©í‘œì  ìƒì„±
                target_index += 1
                if target_index < len(all_targets):
                    next_target = all_targets[target_index]
                else:
                    # ëª¨ë“  ëª©í‘œì ì„ ì‚¬ìš©í–ˆìœ¼ë©´ ìƒˆë¡œìš´ ëª©í‘œì  ìƒì„±
                    next_target = generate_random_target_position(screen_width, screen_height, current_pos=current_target)
                    all_targets.append(next_target)
                
                movement_duration = random.uniform(1.5, 3.0)
                stop_duration = random.uniform(0.8, 1.5)
                test_results["total_movements"] += 1
                
                print(f"ğŸš€ {test_results['total_movements']}ë²ˆì§¸ ì›€ì§ì„ ì‹œì‘!")
                print(f"ğŸ¯ ì´ë™ ê²½ë¡œ: {current_target} â†’ {next_target}")
                print(f"â±ï¸ ì´ë™ ì‹œê°„: {movement_duration:.1f}ì´ˆ, ì •ì§€ ì‹œê°„: {stop_duration:.1f}ì´ˆ")
                print(f"ğŸ” í˜„ì¬ ëª©í‘œ: {current_target}")
                print(f"ğŸ” ë‹¤ìŒ ëª©í‘œ: {next_target}")
        else:
            # ì›€ì§ì„ ìƒíƒœì—ì„œ ì´ë™ ì™„ë£Œ í™•ì¸
            if current_time - movement_start_time >= movement_duration:
                # ì´ë™ ì™„ë£Œ, ì •ì§€ ìƒíƒœë¡œ ì „í™˜
                is_moving = False
                movement_start_time = current_time
                print(f"â¸ï¸ {test_results['total_movements']}ë²ˆì§¸ ì›€ì§ì„ ì™„ë£Œ, ì •ì§€ ìƒíƒœ")
        
        # ëª©í‘œì  ìœ„ì¹˜ ê³„ì‚° (ì›€ì§ì„ ì¤‘ì¼ ë•Œ)
        if is_moving:
            progress = (current_time - movement_start_time) / movement_duration
            start_x, start_y = current_target
            end_x, end_y = next_target
            
            # ë¶€ë“œëŸ¬ìš´ ì´ë™ (ease-in-out)
            if progress < 0.5:
                # ease-in
                t = 2 * progress * progress
            else:
                # ease-out
                t = 1 - 2 * (1 - progress) * (1 - progress)
            
            target_x = int(start_x + (end_x - start_x) * t)
            target_y = int(start_y + (end_y - start_y) * t)
        else:
            target_x, target_y = current_target
        
        # ëª©í‘œì  ê·¸ë¦¬ê¸°
        if is_moving:
            # ì›€ì§ì„ ì¤‘: ë¹¨ê°„ ì 
            cv2.circle(frame_fullscreen, (target_x, target_y), 20, (0, 0, 255), -1)
            cv2.circle(frame_fullscreen, (target_x, target_y), 25, (255, 255, 255), 4)
        else:
            # ì •ì§€ ìƒíƒœ: íŒŒë€ ì 
            cv2.circle(frame_fullscreen, (target_x, target_y), 20, (255, 0, 0), -1)
            cv2.circle(frame_fullscreen, (target_x, target_y), 25, (255, 255, 255), 4)
        
        # ë‹¤ìŒ ëª©í‘œì  í‘œì‹œ (ì‘ì€ ì ìœ¼ë¡œ)
        cv2.circle(frame_fullscreen, next_target, 8, (0, 255, 255), -1)
        cv2.circle(frame_fullscreen, next_target, 12, (255, 255, 255), 2)
        
        if results.multi_face_landmarks:
            landmarks = results.multi_face_landmarks[0].landmark
            h, w = frame.shape[:2]
            
            # í™ì±„ ì¤‘ì‹¬ì  ê³„ì‚°
            left_center = get_iris_center(landmarks, left_iris, w, h)
            right_center = get_iris_center(landmarks, right_iris, w, h)
            
            # ì¢Œí‘œê³„ ë³€í™˜: ì›ë³¸ â†’ ì „ì²´í™”ë©´
            scale_x = screen_width / w
            scale_y = screen_height / h
            
            # ì™¼ìª½ í™ì±„ë¥¼ ì „ì²´í™”ë©´ì— í‘œì‹œ
            left_screen_x = int(left_center[0] * scale_x)
            left_screen_y = int(left_center[1] * scale_y)
            
            # ì˜¤ë¥¸ìª½ í™ì±„ë¥¼ ì „ì²´í™”ë©´ì— í‘œì‹œ
            right_screen_x = int(right_center[0] * scale_x)
            right_screen_y = int(right_center[1] * scale_y)
            
            # í™ì±„ ì¢Œí‘œ ê¸°ë¡
            left_eye_history.append((left_screen_x, left_screen_y))
            right_eye_history.append((right_screen_x, right_screen_y))
            
            # ìµœê·¼ 30ê°œ ì¢Œí‘œë§Œ ìœ ì§€
            if len(left_eye_history) > 30:
                left_eye_history.pop(0)
            if len(right_eye_history) > 30:
                right_eye_history.pop(0)
            
            # ìŠ¤ë¬´ë”© ì ìš©
            if len(left_eye_history) >= 5:
                left_smooth = smooth_coordinates(left_eye_history)
                right_smooth = smooth_coordinates(right_eye_history)
            else:
                left_smooth = (left_screen_x, left_screen_y)
                right_smooth = (right_screen_x, right_screen_y)
            
            # í™ì±„ í‘œì‹œ (ìŠ¤ë¬´ë”©ëœ ì¢Œí‘œ)
            cv2.circle(frame_fullscreen, left_smooth, 4, (0, 255, 0), -1)  # ë…¹ìƒ‰
            cv2.circle(frame_fullscreen, left_smooth, 6, (255, 255, 255), 1)  # í°ìƒ‰ í…Œë‘ë¦¬
            cv2.circle(frame_fullscreen, right_smooth, 4, (0, 255, 0), -1)  # ë…¹ìƒ‰
            cv2.circle(frame_fullscreen, right_smooth, 6, (255, 255, 255), 1)  # í°ìƒ‰ í…Œë‘ë¦¬
            
            # ë™ì²´ì‹œë ¥ ì ìˆ˜ ê³„ì‚°
            eye_sync_score = calculate_eye_movement_sync(left_eye_history, right_eye_history)
            eye_sync_scores.append(eye_sync_score)
            
            # CSV ë°ì´í„° ìˆ˜ì§‘
            csv_row = {
                'frame': frame_count,
                'timestamp': elapsed_time,
                'left_eye_x': left_smooth[0],
                'left_eye_y': left_smooth[1],
                'right_eye_x': right_smooth[0],
                'right_eye_y': right_smooth[1],
                'target_x': target_x,
                'target_y': target_y,
                'is_moving': is_moving,
                'eye_sync_score': eye_sync_score,
                'movement_phase': test_results["total_movements"],
                'reaction_detected': False,
                'reaction_time': None
            }
            
            # ë°˜ì‘ ì‹œê°„ì´ ê°ì§€ëœ ê²½ìš° ê¸°ë¡
            if is_moving and len(left_eye_history) >= 5 and len(right_eye_history) >= 5:
                left_movement = abs(left_smooth[0] - left_eye_history[-5][0]) + abs(left_smooth[1] - left_eye_history[-5][1])
                right_movement = abs(right_smooth[0] - right_eye_history[-5][0]) + abs(right_smooth[1] - right_eye_history[-5][1])
                
                if left_movement > 8 and right_movement > 8:
                    reaction_time = current_time - movement_start_time
                    if reaction_time < 0.5:
                        reaction_times.append(reaction_time)
                        csv_row['reaction_detected'] = True
                        csv_row['reaction_time'] = reaction_time
                        print(f"âš¡ ë°˜ì‘ ì‹œê°„: {reaction_time:.3f}ì´ˆ")
            
            csv_data.append(csv_row)
            frame_count += 1
            

            
            # ì‹œì„  ë°©í–¥ì„ í™”ì‚´í‘œë¡œ í‘œì‹œ
            arrow_color = (255, 0, 0) if is_moving else (0, 255, 0)  # ì›€ì§ì„ ì¤‘: íŒŒë€ìƒ‰, ì •ì§€: ë…¹ìƒ‰
            arrow_thickness = 2
            
            # ì™¼ìª½ í™ì±„ì—ì„œ ëª©í‘œì ê¹Œì§€ í™”ì‚´í‘œ
            cv2.arrowedLine(frame_fullscreen, left_smooth, 
                           (target_x, target_y), arrow_color, arrow_thickness, tipLength=0.3)
            
            # ì˜¤ë¥¸ìª½ í™ì±„ì—ì„œ ëª©í‘œì ê¹Œì§€ í™”ì‚´í‘œ
            cv2.arrowedLine(frame_fullscreen, right_smooth, 
                           (target_x, target_y), arrow_color, arrow_thickness, tipLength=0.3)
            
            # ì •ë³´ í‘œì‹œ
            cv2.putText(frame_fullscreen, f"Left: {left_smooth}", 
                        (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)
            cv2.putText(frame_fullscreen, f"Right: {right_smooth}", 
                        (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)
            cv2.putText(frame_fullscreen, f"Target: ({target_x}, {target_y})", 
                        (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255) if is_moving else (255, 0, 0), 2)
            cv2.putText(frame_fullscreen, f"Time: {elapsed_time:.1f}s", 
                        (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
            cv2.putText(frame_fullscreen, f"Status: {'ì´ë™ì¤‘' if is_moving else 'ì •ì§€'}", 
                        (50, 250), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255) if is_moving else (255, 0, 0), 2)
            cv2.putText(frame_fullscreen, f"Movement: {test_results['total_movements']}", 
                        (50, 300), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
            cv2.putText(frame_fullscreen, f"Eye Sync: {eye_sync_score:.2f}", 
                        (50, 350), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 0), 2)
            
            if reaction_times:
                avg_reaction = np.mean(reaction_times)
                cv2.putText(frame_fullscreen, f"Avg Reaction: {avg_reaction:.3f}s", 
                            (50, 400), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)
        else:
            cv2.putText(frame_fullscreen, "ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤", (50, 50), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 2)
        
        # ì „ì²´í™”ë©´ìœ¼ë¡œ í‘œì‹œ
        cv2.imshow("ëœë¤ ì•„ì´íŠ¸ë˜í‚¹ í…ŒìŠ¤íŠ¸", frame_fullscreen)
        
        # 30ì´ˆ íƒ€ì´ë¨¸ ì²´í¬
        if elapsed_time >= 30:
            print("â° 30ì´ˆ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ê²°ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤...")
            
            # í…ŒìŠ¤íŠ¸ ì™„ë£Œ UI í‘œì‹œ
            print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ UIë¥¼ í‘œì‹œí•©ë‹ˆë‹¤...")
            completion_countdown = 3
            while completion_countdown > 0:
                # ì™„ë£Œ í™”ë©´ ìƒì„±
                completion_screen = np.zeros((screen_height, screen_width, 3), dtype=np.uint8)
                
                # ì œëª©
                cv2.putText(completion_screen, "Test Complete!", 
                            (screen_width//2 - 200, screen_height//2 - 150), 
                            cv2.FONT_HERSHEY_SIMPLEX, 2.5, (0, 255, 0), 4)
                
                # ì¹´ìš´íŠ¸ë‹¤ìš´
                cv2.putText(completion_screen, f"Window closes in {completion_countdown} seconds", 
                            (screen_width//2 - 250, screen_height//2), 
                            cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 3)
                
                # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
                if reaction_times:
                    avg_reaction = np.mean(reaction_times)
                    cv2.putText(completion_screen, f"Average Reaction Time: {avg_reaction:.3f}s", 
                                (screen_width//2 - 200, screen_height//2 + 100), 
                                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)
                
                cv2.imshow("ëœë¤ ì•„ì´íŠ¸ë˜í‚¹ í…ŒìŠ¤íŠ¸", completion_screen)
                cv2.waitKey(1000)  # 1ì´ˆ ëŒ€ê¸°
                completion_countdown -= 1
            
            break
        
        # í‚¤ ì…ë ¥ ì²˜ë¦¬
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            print("ğŸ›‘ ì‚¬ìš©ìê°€ í…ŒìŠ¤íŠ¸ë¥¼ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
            break
    
    cap.release()
    cv2.destroyAllWindows()
    
    # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"ğŸ”„ ì´ ì›€ì§ì„ íšŸìˆ˜: {test_results['total_movements']}")
    
    if reaction_times:
        avg_reaction = np.mean(reaction_times)
        min_reaction = min(reaction_times)
        max_reaction = max(reaction_times)
        print(f"â±ï¸ í‰ê·  ë°˜ì‘ ì‹œê°„: {avg_reaction:.3f}ì´ˆ")
        print(f"â±ï¸ ìµœì†Œ ë°˜ì‘ ì‹œê°„: {min_reaction:.3f}ì´ˆ")
        print(f"â±ï¸ ìµœëŒ€ ë°˜ì‘ ì‹œê°„: {max_reaction:.3f}ì´ˆ")
        
        if avg_reaction < 0.2:
            print("âœ… ë°˜ì‘ ì†ë„: ë§¤ìš° ë¹ ë¦„")
        elif avg_reaction < 0.3:
            print("âœ… ë°˜ì‘ ì†ë„: ë¹ ë¦„")
        elif avg_reaction < 0.4:
            print("âš ï¸ ë°˜ì‘ ì†ë„: ë³´í†µ")
        else:
            print("âŒ ë°˜ì‘ ì†ë„: ëŠë¦¼")
    else:
        print("â±ï¸ ë°˜ì‘ ì‹œê°„: ì¸¡ì • ì‹¤íŒ¨")
    
    if eye_sync_scores:
        avg_sync = np.mean(eye_sync_scores)
        print(f"ğŸ‘€ í‰ê·  ë™ì²´ì‹œë ¥ ì ìˆ˜: {avg_sync:.3f} (1.0 = ì™„ë²½, 0.0 = ì™„ì „ ë¶„ë¦¬)")
        
        if avg_sync > 0.8:
            print("âœ… ë™ì²´ì‹œë ¥: ì •ìƒ")
        elif avg_sync > 0.6:
            print("âš ï¸ ë™ì²´ì‹œë ¥: ê²½ë¯¸í•œ ì´ìƒ")
        else:
            print("âŒ ë™ì²´ì‹œë ¥: ì´ìƒ ê°€ëŠ¥ì„±")
    
    # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    
    # Data_V2/eye_tracking_data í´ë”ì— ì €ì¥
    data_folder = os.path.join(os.path.dirname(os.path.dirname(__file__)), "Data_V2", "eye_tracking_data")
    
    # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    if not os.path.exists(data_folder):
        os.makedirs(data_folder)
        print(f"ğŸ“ {data_folder} í´ë”ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
    
    # ë‚ ì§œë³„ í•˜ìœ„ í´ë” ìƒì„±
    date_folder = os.path.join(data_folder, datetime.now().strftime("%Y-%m"))
    if not os.path.exists(date_folder):
        os.makedirs(date_folder)
        print(f"ğŸ“ {date_folder} í´ë”ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
    
    result_file = os.path.join(date_folder, f"random_eye_tracking_result_{timestamp}.json")
    csv_file = os.path.join(date_folder, f"eye_tracking_data_{timestamp}.csv")
    
    # JSON íŒŒì¼ ì €ì¥ìš© ë°ì´í„° ì¤€ë¹„
    save_data = {
        "timestamp": timestamp,
        "screen_resolution": f"{screen_width}x{screen_height}",
        "test_duration": elapsed_time,
        "total_movements": test_results["total_movements"],
        "reaction_times": reaction_times,
        "average_reaction_time": np.mean(reaction_times) if reaction_times else None,
        "min_reaction_time": min(reaction_times) if reaction_times else None,
        "max_reaction_time": max(reaction_times) if reaction_times else None,
        "average_eye_sync_score": np.mean(eye_sync_scores) if eye_sync_scores else None,
        "eye_sync_scores": eye_sync_scores,
        "total_frames": frame_count,
        "csv_file": csv_file
    }
    
    # JSON íŒŒì¼ ì €ì¥
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(save_data, f, ensure_ascii=False, indent=2)
    
    # CSV íŒŒì¼ ì €ì¥
    if csv_data:
        df = pd.DataFrame(csv_data)
        df.to_csv(csv_file, index=False, encoding='utf-8')
        print(f"ğŸ“Š CSV ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
        print(f"   ğŸ“ ê²½ë¡œ: {csv_file}")
        print(f"   ğŸ“Š ì´ {len(csv_data)}ê°œ í”„ë ˆì„ ë°ì´í„°")
        print(f"   â±ï¸ {len([row for row in csv_data if row['reaction_detected']])}ê°œ ë°˜ì‘ ì‹œê°„ ê¸°ë¡")
    
    print(f"ğŸ’¾ JSON ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
    print(f"   ğŸ“ ê²½ë¡œ: {result_file}")
    print(f"   ğŸ“‚ ì €ì¥ ìœ„ì¹˜: {date_folder}")
    print("âœ… ëœë¤ ì•„ì´íŠ¸ë˜í‚¹ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    run_random_eye_tracking_test()
